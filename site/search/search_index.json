{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Lab4: Filesystem image forensics In this lab, we will inspect filesystem images. We will reason about the filesystem structures, extract useful information (programmatically), and verify their integrity. Objective (primary) experience with filesystem data structures (primary) reverse-engineering binary data Overview This las has two phases. Each phase has its own description and assignments. Interpretation : parse given ext2 images and dump their key data structures. Consistency : check given ext2 images and report any inconsistency Credits : Derived from UCLA CS111","title":"Lab4: Filesystem image forensics"},{"location":"#lab4-filesystem-image-forensics","text":"In this lab, we will inspect filesystem images. We will reason about the filesystem structures, extract useful information (programmatically), and verify their integrity.","title":"Lab4: Filesystem image forensics"},{"location":"#objective","text":"(primary) experience with filesystem data structures (primary) reverse-engineering binary data","title":"Objective"},{"location":"#overview","text":"This las has two phases. Each phase has its own description and assignments. Interpretation : parse given ext2 images and dump their key data structures. Consistency : check given ext2 images and report any inconsistency Credits : Derived from UCLA CS111","title":"Overview"},{"location":"consistency/","text":"File System Consistency Analysis INTRODUCTION: A file system is an example of a large aggregation of complex and highly inter-related data structures. Such systems are often at risk for corruption, most commonly resulting from incomplete execution of what should have been all-or-none updates. Unless we can so cleverly design our data structures and algorithms as to render such errors impossible, it is usually necessary to articulate consistency assertions and develop a utility to audit those systems for consistency, and (where possible) repair any detected anomalies. In part A of this project we wrote a program to examine on-disk data structures and summarize their contents. In this second part, we will analyze those summaries to detect errors and inconsistencies. All previous projects have been implemented in C, which exposes the underlying system calls and is well suited for low level operations on well-defined data structures. This project involves trivial text processing (to read .csv input) and the assembly and processing of an internal state model. While this can certainly be done in C, you may find it easier to do in a higher level language (e.g., Python). You are free implement this project in any language that is supported on the departmental servers (where we will do the testing). RELATION TO READING AND LECTURES: This project more deeply explores the filesystem structures described in Arpaci chapter 39. The images we will be working with are EXT2 file systems, as described in sections 40.2-40.5. This project goes much deeper than the introductory integrity discussion in sections 42.1-2. PROJECT OBJECTIVES: Primary: reinforce the basic file system concepts of directory objects, file objects, and free space. Primary: reinforce the implementation descriptions provided in the text and lectures. Primary: gain experience examining, interpreting and processing information in complex binary data structures. Primary: reinforce the notions of consistency and integrity and apply them to a concrete and non-trivial problem. DELIVERABLES: A single tarball ( .tar.gz ) containing: (at least) one source module that builds/executes cleanly with no errors or warnings. A Makefile to build and run the deliverable program. The higher level targets should be: default ... build your program to produce an executable named lab3b dist ... create the deliverable tarball clean ... delete all programs and output generated by the Makefile , and return the directory to its freshly un-tar-ed state. a README text file containing descriptions of each of the included files and any other information about your submission that you would like to bring to our attention (e.g., research, limitations, features, testing methodology). NOTE: do not create or edit your README file on a Windows system, as the gratuitious carriage-returns may cause processing errors in the auto-grading scripts. PROJECT DESCRIPTION: Write a program to analyze a file system summary (a .csv file in the same format produced for the previous file system project) and report on all discovered inconsistencies. Detected inconsistencies should be reported to standard out. Execution errors (e.g., invalid arguments or unable to open required files) should be reported to standard error. Your executable should be called lab3b and accept a single, required, command line argument, the name of the file to be analyzed. If your language does not require pre-compilation (e.g., Python) create a default rule in your Makefile that merely creates a lab3b link, or prints a success message. If your language does not allow a program to have such a name, include a shell script (named lab3b ) that will run your program. The results grading for this project will be entirely automated, and messages produced in an incorrect format will receive no points. We are providing a sanity check script that will do a simple validation of your package, and confirm correct output for a two-digit number of basic errors. For a simple clean summary, you can use the correct output sample we provided for the previous project. If you want a set of corrupted summaries to test with, you can pull down copies of the summaries (with names like P3B-test_1.csv ) and corresponding correct output (with names like P3B-test_1.err ) used by the sanity check script. Part of your score will be based on your ability to correctly recognize and report on the problems in the supplied file system summaries, but your program will also be tested on several other file systems with a wider range of anomalies. You can lose points for mis-reporting errors, failing to report errors, or for reporting errors that are not present. This is a summary of the errors your program should check for, and a sample error message for each: Block Consistency Audits Every block pointer in an I-node or indirect block should be valid (a legal data block, within the file system) or zero. Examine every single block pointer in every single I-node, direct block, indirect block, double-indirect block, and triple indirect block to ascertain that this is true. Look at all block pointers in the I-node, not merely those within the indicated file size. If any block pointer is not valid (a legal data block within the file system), an error message like one of the following (depending on precisely the nature of the incorrect pointer that is found) should be generated to stdout: INVALID BLOCK 101 IN INODE 13 AT OFFSET 0 INVALID INDIRECT BLOCK 101 IN INODE 13 AT OFFSET 12 INVALID DOUBLE INDIRECT BLOCK 101 IN INODE 13 AT OFFSET 268 INVALID TRIPLE INDIRECT BLOCK 101 IN INODE 13 AT OFFSET 65804 RESERVED INDIRECT BLOCK 3 IN INODE 13 AT OFFSET 12 RESERVED DOUBLE INDIRECT BLOCK 3 IN INODE 13 AT OFFSET 268 RESERVED TRIPLE INDIRECT BLOCK 3 IN INODE 13 AT OFFSET 65804 RESERVED BLOCK 3 IN INODE 13 AT OFFSET 0 An INVALID block is one whose number is less than zero or greater than the highest block in the file system. A RESERVED block is one that could not legally be allocated to any file because it should be reserved for file system metadata (e.g., superblock, cylinder group summary, free block list, ...). The logical OFFSET values are as described for the previous project. Note that the reported offsets should be block numbers (byte offsets divided by 1024). The offset associated with an indirect blocks should be that associated with the first data block it points to (as in the previous project). Every legal data block (every block between the end of the I-nodes and the start of the next group) should appear on on the free block list, or be allocated to exactly one file. Examine the free list to determine whether or not this is the case. If a block is not referenced by any file and is not on the free list, a message like the following should be generated to stdout: UNREFERENCED BLOCK 37 A block that is allocated to some file might also appear on the free list. In this case a message like the following should be generated to stdout: ALLOCATED BLOCK 8 ON FREELIST If a legal block is referenced by multiple files (or even multiple times in a single file), messages like the following (depending on precisely where the references are) should be generated to stdout for each reference to that block: DUPLICATE BLOCK 8 IN INODE 13 AT OFFSET 0 DUPLICATE INDIRECT BLOCK 8 IN INODE 13 AT OFFSET 12 DUPLICATE DOUBLE INDIRECT BLOCK 8 IN INODE 13 AT OFFSET 268 DUPLICATE TRIPLE INDIRECT BLOCK 8 IN INODE 13 AT OFFSET 65804 Note that you will not know that a block is multiply referenced until you find the second reference. You will have to figure out a way to go back and report ALL of the references. We must report all of the references, because each of them is likely to have been corrupted. I-node Allocation Audits We can tell whether or not an I-node is allocated by looking at its type and presence in the CSV file. An allocated I-node will have some valid type (e.g., file or directory). Unallocated I-nodes (whose type should be zero) should not appear in INODE summaries, but should be in the free list. Scan through all of the I-nodes to determine which are valid/allocated. Every unallocated I-Node should be on a free I-node list. Compare your list of allocated/unallocated I-nodes with the free I-node bitmaps, and for each discovered inconsistency, a message like one of the following should be generated to stdout: ALLOCATED INODE 2 ON FREELIST UNALLOCATED INODE 17 NOT ON FREELIST Directory Consistency Audits Every allocated I-node should be referred to by the a number of directory entries that is equal to the reference count recorded in the I-node. Scan all of the directories to enumerate all links. For any allocated I-node whose reference count does not match the number of discovered links, an error message like the following should be generated to stdout: INODE 2 HAS 4 LINKS BUT LINKCOUNT IS 5 This message should also be used to report unreferenced I-nodes: INODE 17 HAS 0 LINKS BUT LINKCOUNT IS 1 Directory entries should only refer to valid and allocated I-nodes. An INVALID I-node is one whose number is less than 1 or greater than the last I-node in the system. While scanning the directory entries, check the validity and allocation status of each referenced I-node. For any reference to an invalid or unallocated I-node, an error message like the following should be generated to stdout: DIRECTORY INODE 2 NAME 'nullEntry' UNALLOCATED INODE 17 DIRECTORY INODE 2 NAME 'bogusEntry' INVALID INODE 26 We also know that every directory should begin with two links, one to itself ( . ) and one to its parent ( .. ). While scanning each directory, check for the correctness of these two links and, for each detected inconsistency, a message like one of the following should be generated to stdout: DIRECTORY INODE 2 NAME '..' LINK TO INODE 11 SHOULD BE 2 DIRECTORY INODE 11 NAME '.' LINK TO INODE 2 SHOULD BE 11 NOTE As in the previous project, the file system summaries we use to test your submission will describe file systems with only a single group. SAMPLE DAMAGED FILE SYSTEM SUMMARIES AND OUTPUT The sanity check script will automatically download a large number of damaged file system summaries. Run your program against them, and compare your output with (what I believe to be) the correct error reports. Note that the sanity check runs are timed. If your program is implemented inefficiently (e.g. too many scans, using too much memory) it may run so slowly as to time out and fail. If this happens to you, examine your approach and look for a more efficient way to obtain the required information. As with the previous project, your output will be sorted before it is compared with the golden results, so the order in which you output errors is unimportant. SUMMARY OF EXIT CODES: 0 ... successful execution, no inconsistencies found. 1 ... unsuccessful execution, bad parameters or system call failure. 2 ... successful execution, inconsistencies found. SUBMISSION: Your README file must include lines of the form: NAME: your (comma separted) name(s) EMAIL: your (comma separted) email address(es) ID: your (comma separted) student ID(s) And, if slip days are allowed on this project, and you want to use some, this too must be included in the README file: SLIPDAYS: #days If, for instance, you wanted to use two slip-days, you would add the following line: SLIPDAYS: 2 Your name, student ID, and email address should also appear as comments at the top of your Makefile and each source file. If this is a team submission, the names, e-mail addresses, and student IDs should be comma-separated. Your tarball should have a name of the form lab3b- studentID .tar.gz . If this is a team submission, only one student ID need appear in the tarball's name. You can sanity check your submission with this test script . Projects that do not pass the test script are likely to receive very poor scores! We will test it on a departmental Linux server. You would be well advised to test your submission on that platform before submitting it.","title":"exp2"},{"location":"consistency/#file-system-consistency-analysis","text":"","title":"File System Consistency Analysis"},{"location":"consistency/#introduction","text":"A file system is an example of a large aggregation of complex and highly inter-related data structures. Such systems are often at risk for corruption, most commonly resulting from incomplete execution of what should have been all-or-none updates. Unless we can so cleverly design our data structures and algorithms as to render such errors impossible, it is usually necessary to articulate consistency assertions and develop a utility to audit those systems for consistency, and (where possible) repair any detected anomalies. In part A of this project we wrote a program to examine on-disk data structures and summarize their contents. In this second part, we will analyze those summaries to detect errors and inconsistencies. All previous projects have been implemented in C, which exposes the underlying system calls and is well suited for low level operations on well-defined data structures. This project involves trivial text processing (to read .csv input) and the assembly and processing of an internal state model. While this can certainly be done in C, you may find it easier to do in a higher level language (e.g., Python). You are free implement this project in any language that is supported on the departmental servers (where we will do the testing).","title":"INTRODUCTION:"},{"location":"consistency/#relation-to-reading-and-lectures","text":"This project more deeply explores the filesystem structures described in Arpaci chapter 39. The images we will be working with are EXT2 file systems, as described in sections 40.2-40.5. This project goes much deeper than the introductory integrity discussion in sections 42.1-2.","title":"RELATION TO READING AND LECTURES:"},{"location":"consistency/#project-objectives","text":"Primary: reinforce the basic file system concepts of directory objects, file objects, and free space. Primary: reinforce the implementation descriptions provided in the text and lectures. Primary: gain experience examining, interpreting and processing information in complex binary data structures. Primary: reinforce the notions of consistency and integrity and apply them to a concrete and non-trivial problem.","title":"PROJECT OBJECTIVES:"},{"location":"consistency/#deliverables","text":"A single tarball ( .tar.gz ) containing: (at least) one source module that builds/executes cleanly with no errors or warnings. A Makefile to build and run the deliverable program. The higher level targets should be: default ... build your program to produce an executable named lab3b dist ... create the deliverable tarball clean ... delete all programs and output generated by the Makefile , and return the directory to its freshly un-tar-ed state. a README text file containing descriptions of each of the included files and any other information about your submission that you would like to bring to our attention (e.g., research, limitations, features, testing methodology). NOTE: do not create or edit your README file on a Windows system, as the gratuitious carriage-returns may cause processing errors in the auto-grading scripts.","title":"DELIVERABLES:"},{"location":"consistency/#project-description","text":"Write a program to analyze a file system summary (a .csv file in the same format produced for the previous file system project) and report on all discovered inconsistencies. Detected inconsistencies should be reported to standard out. Execution errors (e.g., invalid arguments or unable to open required files) should be reported to standard error. Your executable should be called lab3b and accept a single, required, command line argument, the name of the file to be analyzed. If your language does not require pre-compilation (e.g., Python) create a default rule in your Makefile that merely creates a lab3b link, or prints a success message. If your language does not allow a program to have such a name, include a shell script (named lab3b ) that will run your program. The results grading for this project will be entirely automated, and messages produced in an incorrect format will receive no points. We are providing a sanity check script that will do a simple validation of your package, and confirm correct output for a two-digit number of basic errors. For a simple clean summary, you can use the correct output sample we provided for the previous project. If you want a set of corrupted summaries to test with, you can pull down copies of the summaries (with names like P3B-test_1.csv ) and corresponding correct output (with names like P3B-test_1.err ) used by the sanity check script. Part of your score will be based on your ability to correctly recognize and report on the problems in the supplied file system summaries, but your program will also be tested on several other file systems with a wider range of anomalies. You can lose points for mis-reporting errors, failing to report errors, or for reporting errors that are not present. This is a summary of the errors your program should check for, and a sample error message for each:","title":"PROJECT DESCRIPTION:"},{"location":"consistency/#block-consistency-audits","text":"Every block pointer in an I-node or indirect block should be valid (a legal data block, within the file system) or zero. Examine every single block pointer in every single I-node, direct block, indirect block, double-indirect block, and triple indirect block to ascertain that this is true. Look at all block pointers in the I-node, not merely those within the indicated file size. If any block pointer is not valid (a legal data block within the file system), an error message like one of the following (depending on precisely the nature of the incorrect pointer that is found) should be generated to stdout: INVALID BLOCK 101 IN INODE 13 AT OFFSET 0 INVALID INDIRECT BLOCK 101 IN INODE 13 AT OFFSET 12 INVALID DOUBLE INDIRECT BLOCK 101 IN INODE 13 AT OFFSET 268 INVALID TRIPLE INDIRECT BLOCK 101 IN INODE 13 AT OFFSET 65804 RESERVED INDIRECT BLOCK 3 IN INODE 13 AT OFFSET 12 RESERVED DOUBLE INDIRECT BLOCK 3 IN INODE 13 AT OFFSET 268 RESERVED TRIPLE INDIRECT BLOCK 3 IN INODE 13 AT OFFSET 65804 RESERVED BLOCK 3 IN INODE 13 AT OFFSET 0 An INVALID block is one whose number is less than zero or greater than the highest block in the file system. A RESERVED block is one that could not legally be allocated to any file because it should be reserved for file system metadata (e.g., superblock, cylinder group summary, free block list, ...). The logical OFFSET values are as described for the previous project. Note that the reported offsets should be block numbers (byte offsets divided by 1024). The offset associated with an indirect blocks should be that associated with the first data block it points to (as in the previous project). Every legal data block (every block between the end of the I-nodes and the start of the next group) should appear on on the free block list, or be allocated to exactly one file. Examine the free list to determine whether or not this is the case. If a block is not referenced by any file and is not on the free list, a message like the following should be generated to stdout: UNREFERENCED BLOCK 37 A block that is allocated to some file might also appear on the free list. In this case a message like the following should be generated to stdout: ALLOCATED BLOCK 8 ON FREELIST If a legal block is referenced by multiple files (or even multiple times in a single file), messages like the following (depending on precisely where the references are) should be generated to stdout for each reference to that block: DUPLICATE BLOCK 8 IN INODE 13 AT OFFSET 0 DUPLICATE INDIRECT BLOCK 8 IN INODE 13 AT OFFSET 12 DUPLICATE DOUBLE INDIRECT BLOCK 8 IN INODE 13 AT OFFSET 268 DUPLICATE TRIPLE INDIRECT BLOCK 8 IN INODE 13 AT OFFSET 65804 Note that you will not know that a block is multiply referenced until you find the second reference. You will have to figure out a way to go back and report ALL of the references. We must report all of the references, because each of them is likely to have been corrupted.","title":"Block Consistency Audits"},{"location":"consistency/#i-node-allocation-audits","text":"We can tell whether or not an I-node is allocated by looking at its type and presence in the CSV file. An allocated I-node will have some valid type (e.g., file or directory). Unallocated I-nodes (whose type should be zero) should not appear in INODE summaries, but should be in the free list. Scan through all of the I-nodes to determine which are valid/allocated. Every unallocated I-Node should be on a free I-node list. Compare your list of allocated/unallocated I-nodes with the free I-node bitmaps, and for each discovered inconsistency, a message like one of the following should be generated to stdout: ALLOCATED INODE 2 ON FREELIST UNALLOCATED INODE 17 NOT ON FREELIST","title":"I-node Allocation Audits"},{"location":"consistency/#directory-consistency-audits","text":"Every allocated I-node should be referred to by the a number of directory entries that is equal to the reference count recorded in the I-node. Scan all of the directories to enumerate all links. For any allocated I-node whose reference count does not match the number of discovered links, an error message like the following should be generated to stdout: INODE 2 HAS 4 LINKS BUT LINKCOUNT IS 5 This message should also be used to report unreferenced I-nodes: INODE 17 HAS 0 LINKS BUT LINKCOUNT IS 1 Directory entries should only refer to valid and allocated I-nodes. An INVALID I-node is one whose number is less than 1 or greater than the last I-node in the system. While scanning the directory entries, check the validity and allocation status of each referenced I-node. For any reference to an invalid or unallocated I-node, an error message like the following should be generated to stdout: DIRECTORY INODE 2 NAME 'nullEntry' UNALLOCATED INODE 17 DIRECTORY INODE 2 NAME 'bogusEntry' INVALID INODE 26 We also know that every directory should begin with two links, one to itself ( . ) and one to its parent ( .. ). While scanning each directory, check for the correctness of these two links and, for each detected inconsistency, a message like one of the following should be generated to stdout: DIRECTORY INODE 2 NAME '..' LINK TO INODE 11 SHOULD BE 2 DIRECTORY INODE 11 NAME '.' LINK TO INODE 2 SHOULD BE 11","title":"Directory Consistency Audits"},{"location":"consistency/#note","text":"As in the previous project, the file system summaries we use to test your submission will describe file systems with only a single group.","title":"NOTE"},{"location":"consistency/#sample-damaged-file-system-summaries-and-output","text":"The sanity check script will automatically download a large number of damaged file system summaries. Run your program against them, and compare your output with (what I believe to be) the correct error reports. Note that the sanity check runs are timed. If your program is implemented inefficiently (e.g. too many scans, using too much memory) it may run so slowly as to time out and fail. If this happens to you, examine your approach and look for a more efficient way to obtain the required information. As with the previous project, your output will be sorted before it is compared with the golden results, so the order in which you output errors is unimportant.","title":"SAMPLE DAMAGED FILE SYSTEM SUMMARIES AND OUTPUT"},{"location":"consistency/#summary-of-exit-codes","text":"0 ... successful execution, no inconsistencies found. 1 ... unsuccessful execution, bad parameters or system call failure. 2 ... successful execution, inconsistencies found.","title":"SUMMARY OF EXIT CODES:"},{"location":"consistency/#submission","text":"Your README file must include lines of the form: NAME: your (comma separted) name(s) EMAIL: your (comma separted) email address(es) ID: your (comma separted) student ID(s) And, if slip days are allowed on this project, and you want to use some, this too must be included in the README file: SLIPDAYS: #days If, for instance, you wanted to use two slip-days, you would add the following line: SLIPDAYS: 2 Your name, student ID, and email address should also appear as comments at the top of your Makefile and each source file. If this is a team submission, the names, e-mail addresses, and student IDs should be comma-separated. Your tarball should have a name of the form lab3b- studentID .tar.gz . If this is a team submission, only one student ID need appear in the tarball's name. You can sanity check your submission with this test script . Projects that do not pass the test script are likely to receive very poor scores! We will test it on a departmental Linux server. You would be well advised to test your submission on that platform before submitting it.","title":"SUBMISSION:"},{"location":"interpretation/","text":"File System Interpretation INTRODUCTION: We are all familiar with the characteristics of the files and directories in which we store all of our data. As with many other persistent objects, their functionality, generality, performance and robustness all derive from the underlying data structures used to implement them. In this project we will design and implement a program to read the on-disk representation of a file system, analyze it, and summarize its contents. In the next project, we will write a program to analyze this summary for evidence of corruption. This project can be broken into two major steps: Understand the on-disk data format of the EXT2 file system. We will mount a provided image file on your own Linux system and explore it with familiar file navigation commands and debugfs(8) . Write a program to analyze the file system in that image file and output a summary to standard out (describing the super block, groups, free-lists, inodes, indirect blocks, and directories). The second part may involve much more code than we have written in previous projects, but the first part is (by far) the more difficult. Once the underlying data structures are understood, the actual code is likely to be fairly simple. RELATION TO READING AND LECTURES: This project more deeply explores the filesystem structures described in Arpaci chapter 39. The images we will be working with are EXT2 file systems, as described in sections 40.2-40.5. The lectures on file systems, file system performance, and reliability describe why data structures like those in this project are used to manage file systems. PROJECT OBJECTIVES: Primary: reinforce the basic file system concepts of directory objects, file objects, and free space. Primary: reinforce the implementation descriptions provided in the text and lectures. Primary: gain experience researching, examining, interpreting and processing information in complex binary data structures . Primary: gain experience with examining interpreted and raw hex dumps of complex data structures as a means of developing an understanding of those data structures. Secondary: gain practical experience with typical on-disk file system data formats. DELIVERABLES: A single tarball ( .tar.gz ) containing: (at least) one C/C++ source module that compiles cleanly with no errors or warnings). A Makefile to build and run the deliverable program. The higher level targets should be: default ... compile your program (with the -Wall and -Wextra options) to produce an executable named lab3a dist ... create the deliverable tarball clean ... delete all programs and output generated by the Makefile . a README text file containing descriptions of each of the included files and any other information about your submission that you would like to bring to our attention (e.g., research, limitations, features, testing methodology). PROJECT DESCRIPTION: Historically, file systems were almost always been implemented as part of the operating system, running in kernel mode. Kernel code is expensive to develop, difficult to test, and prone to catastrophic failures. Within the past 15 years or so, new developments have made it possible to implement file systems in user mode, improving maintainability, and in some cases delivering even better performance than could be achieved with kernel code. All of this project will be done as user-mode software. To ensure data privacy and integrity, file system disks are generally protected from access by ordinary applications. Linux supports the creation, mounting, checking, and debugging of file systems stored in ordinary files. In this project, we will provide EXT2 file system images in ordinary files. Because they are in ordinary files (rather than protected disks) you can access/operate on those file system images with ordinary user mode code. PREPARATION To perform this assignment, you may need to study a few things: debugfs(8) , a tool for exploring on-disk file system structures. pread(2) , an alternative to read(2) for random-access file processing. a comprehensive overview of the EXT2 file system format. a slightly simplified version of the Linux header file that defines the format of the EXT2 file system. Do not assume that the standard header file will be available on the test system. Please use this header file and include it in your submission. You cannot modify this header file, but you are free to add new files of your own. PART 1: Exploring an EXT2 Image In order to mount and explore a file system (even one stored in an ordinary file) you will need the ability to run privileged commands (e.g., mount(8) ). Since you will not have sudo(8) access on departmental servers, you will have to do this exploration on your own personal Linux system. Download this (1-2MB) file system image , and mount it (read only) onto your own Linux system, with the following commands: mkdir fs sudo mount -o ro,loop ext2_image fs The loop option means that the file system image is stored in a file rather than on a device. The ro option means read only , to prevent you from accidentally changing the image. Now, you can navigate the file system, just like an ordinary directory, with commands like ls(1) , cat(1) , and cd(1) . After you are done with it, you can unmount with the following command: sudo umount fs Before you start writing your C/C++ program to interpret the diskimage file, you can explore it further using debugfs(8) (on your own Linux system). You will, in the process of writing your code, surely encounter many questions about how to interpret the values in various fields. Reading the specifications is seldom enough to enable us to fully understand complex data structures. Welcome to the real world! Learning how to complement research with examination and experimentation to understand a complex system is a skill that you are expected to develop and demonstrate in this project. The supplied images and exploration tools can be used to examine real instances of super blocks, group summaries, I-nodes, directories, etc. Some particularly helpful debugfs(8) commands are: stats , stat , bd , testi , and testb . While debugfs can interpret data structures for you, you may find that a simple hex dump of the associated block provides you with more detailed information. Warnings If you mount the trivial.img image read/write, even read commands (like ls(1) ) will cause changes to I-node access times. If you want to be able to compare your analysis with the golden trivial.csv output we have provided, you must work from an unmodified version of trivial.img . To ensure you are correctly interpreting the file system image, we have included many unusual things, which might not be properly handled by a na\u00efve implementation: sparse files with large unallocated areas between allocated blocks very large files allocated data blocks full of zeroes unallocated blocks containing valid data files with data beyond their length files with long names files with syntactically strange or non-ASCII names directories that span multiple blocks, go beyond the direct blocks, and have obsolete entries for deleted files All of these are completely legal and do not represent any sort of corruption. PART 2: Summarizing an EXT2 Image In this step, you will write a C/C++ program called lab3a that: Reads a file system image, whose name is specified as a command line argument. For example, we may run your program with the above file system image using the a command like: ``` ./lab3a EXT2_test.img ``` Analyzes the provided file system image and produces (to standard out) CSV summaries of what it finds. The contents of these CSV lines described below. Your program must output these files with exactly the same formats as shown below. We will use sort(1) and diff(1) to compare your csv output with ours, so the order of output lines does not matter, but a different format (even extra white space) will make your program fail the test. Please note that, even if you cannot mount the provided image file and run debugfs on departmental servers, your lab3a program should, like previous assignments, be able to run on departmental servers. There are six types of output lines that your program should produce, each summarizing a different part of the file system. Remember, you can always check your program's output against debugfs 's output. All the information required for the summary can be manually found and checked by using debugfs. We have also included (for testing purposes) a much smaller image (trivial.img) as well as a correct output summary . You are free to produce additional commentary to stderr, but only file system summary information should be logged to stdout. superblock summary A single new-line terminated line, comprised of eight comma-separated fields (with no white-space), summarizing the key file system parameters: SUPERBLOCK total number of blocks (decimal) total number of i-nodes (decimal) block size (in bytes, decimal) i-node size (in bytes, decimal) blocks per group (decimal) i-nodes per group (decimal) first non-reserved i-node (decimal) group summary Scan each of the groups in the file system. For each group, produce a new-line terminated line for each group, each comprised of nine comma-separated fields (with no white space), summarizing its contents. GROUP group number (decimal, starting from zero) total number of blocks in this group (decimal) total number of i-nodes in this group (decimal) number of free blocks (decimal) number of free i-nodes (decimal) block number of free block bitmap for this group (decimal) block number of free i-node bitmap for this group (decimal) block number of first block of i-nodes in this group (decimal) Note that most Berkeley-derived file systems (like EXT2) support both blocks and fragments, which may have different sizes. The block is the preferred unit of allocation. But in some cases, fragments may be used (to reduce internal fragmentation loss). Block addresses and the free block list entries are based on the fragment size, rather than the block size. But, in the images we give you, the block and fragment sizes will be the same. One of the major features included EXT2 file systems is support for multiple cylinder groups: all cylinder groups but the last have the same number of blocks and I-nodes; the last has the residue (e.g., blocks/fs modulo blocks/group). each group, in addition to its group summary, also (for redundancy) starts with a copy of the file system superblock. But, in the images we give you, there will be only a single group. free block entries Scan the free block bitmap for each group. For each free block, produce a new-line terminated line, with two comma-separated fields (with no white space). BFREE number of the free block (decimal) Take care to verify that you: understand whether 1 means allocated or free. have correctly understood the block number to which the first bit corresponds. know how many blocks are in each group, and do not interpret more bits than there are blocks in the group. free I-node entries Scan the free I-node bitmap for each group. For each free I-node, produce a new-line terminated line, with two comma-separated fields (with no white space). IFREE number of the free I-node (decimal) Take care to verify that you: understand whether 1 means allocated or free. have correctly understood the I-node number to which the first bit corresponds. know how many I-nodes are in each group, and do not interpret more bits than there are I-nodes in the group. I-node summary Scan the I-nodes for each group. For each allocated (non-zero mode and non-zero link count) I-node, produce a new-line terminated line, with up to 27 comma-separated fields (with no white space). The first twelve fields are i-node attributes: INODE inode number (decimal) file type ('f' for file, 'd' for directory, 's' for symbolic link, '?\" for anything else) mode (low order 12-bits, octal ... suggested format \"%o\") owner (decimal) group (decimal) link count (decimal) time of last I-node change (mm/dd/yy hh:mm:ss, GMT) modification time (mm/dd/yy hh:mm:ss, GMT) time of last access (mm/dd/yy hh:mm:ss, GMT) file size (decimal) number of (512 byte) blocks of disk space (decimal) taken up by this file The number of blocks (field 12) should contain the same value as the i_blocks field of the I-node. There are a few interesting and non-obvious things about this number: This number is in units of 512 byte blocks, even if the file system block size is something else (e.g. 1024 or 4096 byte blocks). This number (times 512) may be smaller than the file size, as it includes only blocks that have actually been allocated to the file. A very large file might be sparse , in that some parts of the file may not have actually been written, and take up no disk space, but will read back as zeroes. This number (times 512) may be larger than the file size because it includes not only data blocks, but (single, double, and triple) indirect blocks that point to data blocks. For ordinary files (type 'f') and directories (type 'd') the next fifteen fields are block addresses (decimal, 12 direct, one indirect, one double indirect, one triple indirect). Symbolic links are a little more complicated. If the file length is less than the size of the block pointers (60 bytes) the file will contain zero data blocks, and the name is stored in the space normally occupied by the block pointers. If this is the case, the fifteen block pointers need not be printed. directory entries For each directory I-node, scan every data block. For each valid (non-zero I-node number) directory entry, produce a new-line terminated line, with seven comma-separated fields (no white space). DIRENT parent inode number (decimal) ... the I-node number of the directory that contains this entry logical byte offset (decimal) of this entry within the directory inode number of the referenced file (decimal) entry length (decimal) name length (decimal) name (string, surrounded by single-quotes). Don't worry about escaping, we promise there will be no single-quotes or commas in any of the file names. indirect block references The I-node summary contains a list of all 12 blocks, and the primary single, double, and triple indirect blocks. We also need to know about the blocks that are pointed to by those indirect blocks. For each file or directory I-node, scan the single indirect blocks and (recursively) the double and triple indirect blocks. For each non-zero block pointer you find, produce a new-line terminated line with six comma-separated fields (no white space). INDIRECT I-node number of the owning file (decimal) (decimal) level of indirection for the block being scanned ... 1 for single indirect, 2 for double indirect, 3 for triple logical block offset (decimal) represented by the referenced block. If the referenced block is a data block, this is the logical block offset of that block within the file. If the referenced block is a single- or double-indirect block, this is the same as the logical offset of the first data block to which it refers. block number of the (1, 2, 3) indirect block being scanned (decimal) . . . not the highest level block (in the recursive scan), but the lower level block that contains the block reference reported by this entry. block number of the referenced block (decimal) Logical block is a commonly used term. It ignores physical file structure (where data is actually stored, indirect blocks, sparseness, etc) and views the data in the file as a (logical) stream of bytes. If the block size was 1K (1024 bytes): bytes 0-1023 would be in logical block 0 bytes 1024-2047 would be in logical block 1 bytes 2048-3071 would be in logical block 2 ... You can confirm your understanding of logical block numbers by looking at the INDIRECT entries in the sample output. If an I-node contains a triple indirect block: the triple indirect block number would be included in the INODE summary. INDIRECT entries (with level 3) would be produced for each double indirect block pointed to by that triple indirect block. INDIRECT entries (with level 2) would be produced for each indirect block pointed to by one of those double indirect blocks. INDIRECT entries (with level 1) would be produced for each data block pointed to by one of those indirect blocks. Sample Output We have provided a very simple test file system image as well as a correct output summary that you can download and test with. Your program should be able to generate (modulo line ordering) the same output. The grading program will run your program on a variety of other file system images, and check whether or not your output is identical to the golden output. Any differences (even white space or a case error) will result in a loss of all points for that test. SUMMARY OF EXIT CODES: 0 . . . analysis successful 1 . . . bad arguments 2 . . . corruption detected or other processing errors","title":"exp1"},{"location":"interpretation/#file-system-interpretation","text":"","title":"File System Interpretation"},{"location":"interpretation/#introduction","text":"We are all familiar with the characteristics of the files and directories in which we store all of our data. As with many other persistent objects, their functionality, generality, performance and robustness all derive from the underlying data structures used to implement them. In this project we will design and implement a program to read the on-disk representation of a file system, analyze it, and summarize its contents. In the next project, we will write a program to analyze this summary for evidence of corruption. This project can be broken into two major steps: Understand the on-disk data format of the EXT2 file system. We will mount a provided image file on your own Linux system and explore it with familiar file navigation commands and debugfs(8) . Write a program to analyze the file system in that image file and output a summary to standard out (describing the super block, groups, free-lists, inodes, indirect blocks, and directories). The second part may involve much more code than we have written in previous projects, but the first part is (by far) the more difficult. Once the underlying data structures are understood, the actual code is likely to be fairly simple.","title":"INTRODUCTION:"},{"location":"interpretation/#relation-to-reading-and-lectures","text":"This project more deeply explores the filesystem structures described in Arpaci chapter 39. The images we will be working with are EXT2 file systems, as described in sections 40.2-40.5. The lectures on file systems, file system performance, and reliability describe why data structures like those in this project are used to manage file systems.","title":"RELATION TO READING AND LECTURES:"},{"location":"interpretation/#project-objectives","text":"Primary: reinforce the basic file system concepts of directory objects, file objects, and free space. Primary: reinforce the implementation descriptions provided in the text and lectures. Primary: gain experience researching, examining, interpreting and processing information in complex binary data structures . Primary: gain experience with examining interpreted and raw hex dumps of complex data structures as a means of developing an understanding of those data structures. Secondary: gain practical experience with typical on-disk file system data formats.","title":"PROJECT OBJECTIVES:"},{"location":"interpretation/#deliverables","text":"A single tarball ( .tar.gz ) containing: (at least) one C/C++ source module that compiles cleanly with no errors or warnings). A Makefile to build and run the deliverable program. The higher level targets should be: default ... compile your program (with the -Wall and -Wextra options) to produce an executable named lab3a dist ... create the deliverable tarball clean ... delete all programs and output generated by the Makefile . a README text file containing descriptions of each of the included files and any other information about your submission that you would like to bring to our attention (e.g., research, limitations, features, testing methodology).","title":"DELIVERABLES:"},{"location":"interpretation/#project-description","text":"Historically, file systems were almost always been implemented as part of the operating system, running in kernel mode. Kernel code is expensive to develop, difficult to test, and prone to catastrophic failures. Within the past 15 years or so, new developments have made it possible to implement file systems in user mode, improving maintainability, and in some cases delivering even better performance than could be achieved with kernel code. All of this project will be done as user-mode software. To ensure data privacy and integrity, file system disks are generally protected from access by ordinary applications. Linux supports the creation, mounting, checking, and debugging of file systems stored in ordinary files. In this project, we will provide EXT2 file system images in ordinary files. Because they are in ordinary files (rather than protected disks) you can access/operate on those file system images with ordinary user mode code.","title":"PROJECT DESCRIPTION:"},{"location":"interpretation/#preparation","text":"To perform this assignment, you may need to study a few things: debugfs(8) , a tool for exploring on-disk file system structures. pread(2) , an alternative to read(2) for random-access file processing. a comprehensive overview of the EXT2 file system format. a slightly simplified version of the Linux header file that defines the format of the EXT2 file system. Do not assume that the standard header file will be available on the test system. Please use this header file and include it in your submission. You cannot modify this header file, but you are free to add new files of your own.","title":"PREPARATION"},{"location":"interpretation/#part-1-exploring-an-ext2-image","text":"In order to mount and explore a file system (even one stored in an ordinary file) you will need the ability to run privileged commands (e.g., mount(8) ). Since you will not have sudo(8) access on departmental servers, you will have to do this exploration on your own personal Linux system. Download this (1-2MB) file system image , and mount it (read only) onto your own Linux system, with the following commands: mkdir fs sudo mount -o ro,loop ext2_image fs The loop option means that the file system image is stored in a file rather than on a device. The ro option means read only , to prevent you from accidentally changing the image. Now, you can navigate the file system, just like an ordinary directory, with commands like ls(1) , cat(1) , and cd(1) . After you are done with it, you can unmount with the following command: sudo umount fs Before you start writing your C/C++ program to interpret the diskimage file, you can explore it further using debugfs(8) (on your own Linux system). You will, in the process of writing your code, surely encounter many questions about how to interpret the values in various fields. Reading the specifications is seldom enough to enable us to fully understand complex data structures. Welcome to the real world! Learning how to complement research with examination and experimentation to understand a complex system is a skill that you are expected to develop and demonstrate in this project. The supplied images and exploration tools can be used to examine real instances of super blocks, group summaries, I-nodes, directories, etc. Some particularly helpful debugfs(8) commands are: stats , stat , bd , testi , and testb . While debugfs can interpret data structures for you, you may find that a simple hex dump of the associated block provides you with more detailed information.","title":"PART 1: Exploring an EXT2 Image"},{"location":"interpretation/#warnings","text":"If you mount the trivial.img image read/write, even read commands (like ls(1) ) will cause changes to I-node access times. If you want to be able to compare your analysis with the golden trivial.csv output we have provided, you must work from an unmodified version of trivial.img . To ensure you are correctly interpreting the file system image, we have included many unusual things, which might not be properly handled by a na\u00efve implementation: sparse files with large unallocated areas between allocated blocks very large files allocated data blocks full of zeroes unallocated blocks containing valid data files with data beyond their length files with long names files with syntactically strange or non-ASCII names directories that span multiple blocks, go beyond the direct blocks, and have obsolete entries for deleted files All of these are completely legal and do not represent any sort of corruption.","title":"Warnings"},{"location":"interpretation/#part-2-summarizing-an-ext2-image","text":"In this step, you will write a C/C++ program called lab3a that: Reads a file system image, whose name is specified as a command line argument. For example, we may run your program with the above file system image using the a command like: ``` ./lab3a EXT2_test.img ``` Analyzes the provided file system image and produces (to standard out) CSV summaries of what it finds. The contents of these CSV lines described below. Your program must output these files with exactly the same formats as shown below. We will use sort(1) and diff(1) to compare your csv output with ours, so the order of output lines does not matter, but a different format (even extra white space) will make your program fail the test. Please note that, even if you cannot mount the provided image file and run debugfs on departmental servers, your lab3a program should, like previous assignments, be able to run on departmental servers. There are six types of output lines that your program should produce, each summarizing a different part of the file system. Remember, you can always check your program's output against debugfs 's output. All the information required for the summary can be manually found and checked by using debugfs. We have also included (for testing purposes) a much smaller image (trivial.img) as well as a correct output summary . You are free to produce additional commentary to stderr, but only file system summary information should be logged to stdout.","title":"PART 2: Summarizing an EXT2 Image"},{"location":"interpretation/#superblock-summary","text":"A single new-line terminated line, comprised of eight comma-separated fields (with no white-space), summarizing the key file system parameters: SUPERBLOCK total number of blocks (decimal) total number of i-nodes (decimal) block size (in bytes, decimal) i-node size (in bytes, decimal) blocks per group (decimal) i-nodes per group (decimal) first non-reserved i-node (decimal)","title":"superblock summary"},{"location":"interpretation/#group-summary","text":"Scan each of the groups in the file system. For each group, produce a new-line terminated line for each group, each comprised of nine comma-separated fields (with no white space), summarizing its contents. GROUP group number (decimal, starting from zero) total number of blocks in this group (decimal) total number of i-nodes in this group (decimal) number of free blocks (decimal) number of free i-nodes (decimal) block number of free block bitmap for this group (decimal) block number of free i-node bitmap for this group (decimal) block number of first block of i-nodes in this group (decimal) Note that most Berkeley-derived file systems (like EXT2) support both blocks and fragments, which may have different sizes. The block is the preferred unit of allocation. But in some cases, fragments may be used (to reduce internal fragmentation loss). Block addresses and the free block list entries are based on the fragment size, rather than the block size. But, in the images we give you, the block and fragment sizes will be the same. One of the major features included EXT2 file systems is support for multiple cylinder groups: all cylinder groups but the last have the same number of blocks and I-nodes; the last has the residue (e.g., blocks/fs modulo blocks/group). each group, in addition to its group summary, also (for redundancy) starts with a copy of the file system superblock. But, in the images we give you, there will be only a single group.","title":"group summary"},{"location":"interpretation/#free-block-entries","text":"Scan the free block bitmap for each group. For each free block, produce a new-line terminated line, with two comma-separated fields (with no white space). BFREE number of the free block (decimal) Take care to verify that you: understand whether 1 means allocated or free. have correctly understood the block number to which the first bit corresponds. know how many blocks are in each group, and do not interpret more bits than there are blocks in the group.","title":"free block entries"},{"location":"interpretation/#free-i-node-entries","text":"Scan the free I-node bitmap for each group. For each free I-node, produce a new-line terminated line, with two comma-separated fields (with no white space). IFREE number of the free I-node (decimal) Take care to verify that you: understand whether 1 means allocated or free. have correctly understood the I-node number to which the first bit corresponds. know how many I-nodes are in each group, and do not interpret more bits than there are I-nodes in the group.","title":"free I-node entries"},{"location":"interpretation/#i-node-summary","text":"Scan the I-nodes for each group. For each allocated (non-zero mode and non-zero link count) I-node, produce a new-line terminated line, with up to 27 comma-separated fields (with no white space). The first twelve fields are i-node attributes: INODE inode number (decimal) file type ('f' for file, 'd' for directory, 's' for symbolic link, '?\" for anything else) mode (low order 12-bits, octal ... suggested format \"%o\") owner (decimal) group (decimal) link count (decimal) time of last I-node change (mm/dd/yy hh:mm:ss, GMT) modification time (mm/dd/yy hh:mm:ss, GMT) time of last access (mm/dd/yy hh:mm:ss, GMT) file size (decimal) number of (512 byte) blocks of disk space (decimal) taken up by this file The number of blocks (field 12) should contain the same value as the i_blocks field of the I-node. There are a few interesting and non-obvious things about this number: This number is in units of 512 byte blocks, even if the file system block size is something else (e.g. 1024 or 4096 byte blocks). This number (times 512) may be smaller than the file size, as it includes only blocks that have actually been allocated to the file. A very large file might be sparse , in that some parts of the file may not have actually been written, and take up no disk space, but will read back as zeroes. This number (times 512) may be larger than the file size because it includes not only data blocks, but (single, double, and triple) indirect blocks that point to data blocks. For ordinary files (type 'f') and directories (type 'd') the next fifteen fields are block addresses (decimal, 12 direct, one indirect, one double indirect, one triple indirect). Symbolic links are a little more complicated. If the file length is less than the size of the block pointers (60 bytes) the file will contain zero data blocks, and the name is stored in the space normally occupied by the block pointers. If this is the case, the fifteen block pointers need not be printed.","title":"I-node summary"},{"location":"interpretation/#directory-entries","text":"For each directory I-node, scan every data block. For each valid (non-zero I-node number) directory entry, produce a new-line terminated line, with seven comma-separated fields (no white space). DIRENT parent inode number (decimal) ... the I-node number of the directory that contains this entry logical byte offset (decimal) of this entry within the directory inode number of the referenced file (decimal) entry length (decimal) name length (decimal) name (string, surrounded by single-quotes). Don't worry about escaping, we promise there will be no single-quotes or commas in any of the file names.","title":"directory entries"},{"location":"interpretation/#indirect-block-references","text":"The I-node summary contains a list of all 12 blocks, and the primary single, double, and triple indirect blocks. We also need to know about the blocks that are pointed to by those indirect blocks. For each file or directory I-node, scan the single indirect blocks and (recursively) the double and triple indirect blocks. For each non-zero block pointer you find, produce a new-line terminated line with six comma-separated fields (no white space). INDIRECT I-node number of the owning file (decimal) (decimal) level of indirection for the block being scanned ... 1 for single indirect, 2 for double indirect, 3 for triple logical block offset (decimal) represented by the referenced block. If the referenced block is a data block, this is the logical block offset of that block within the file. If the referenced block is a single- or double-indirect block, this is the same as the logical offset of the first data block to which it refers. block number of the (1, 2, 3) indirect block being scanned (decimal) . . . not the highest level block (in the recursive scan), but the lower level block that contains the block reference reported by this entry. block number of the referenced block (decimal) Logical block is a commonly used term. It ignores physical file structure (where data is actually stored, indirect blocks, sparseness, etc) and views the data in the file as a (logical) stream of bytes. If the block size was 1K (1024 bytes): bytes 0-1023 would be in logical block 0 bytes 1024-2047 would be in logical block 1 bytes 2048-3071 would be in logical block 2 ... You can confirm your understanding of logical block numbers by looking at the INDIRECT entries in the sample output. If an I-node contains a triple indirect block: the triple indirect block number would be included in the INODE summary. INDIRECT entries (with level 3) would be produced for each double indirect block pointed to by that triple indirect block. INDIRECT entries (with level 2) would be produced for each indirect block pointed to by one of those double indirect blocks. INDIRECT entries (with level 1) would be produced for each data block pointed to by one of those indirect blocks.","title":"indirect block references"},{"location":"interpretation/#sample-output","text":"We have provided a very simple test file system image as well as a correct output summary that you can download and test with. Your program should be able to generate (modulo line ordering) the same output. The grading program will run your program on a variety of other file system images, and check whether or not your output is identical to the golden output. Any differences (even white space or a case error) will result in a loss of all points for that test.","title":"Sample Output"},{"location":"interpretation/#summary-of-exit-codes","text":"0 . . . analysis successful 1 . . . bad arguments 2 . . . corruption detected or other processing errors","title":"SUMMARY OF EXIT CODES:"},{"location":"lite/","text":"p4 lite: Filesystem inspection In this lab, we will inspect filesystem images. We will reason about how filedata and metadata are stored and maintained. This is a light version of \"Lab4: filesystem image forensics\". Objectives (primary) Reinforcing understanding of ext2 (secondary) Familiarizing with Linux file tools Roadmap Mount an ext2 filesystem image with a few dir/files. Use Linux tools to examine key data structures: inodes/bitmaps\u2026 Show how such a filesystem image is created Prerequisites Required environment Fiddling with a whole filesystem (and disk images) requires the root privilege. Linux/Mac users: do this lab either on your local box which you have root. Or do it on the server, inside a QEMU emulator. The problem with QEMU: you will need a system image with all the utilities, e.g. dumpe2fs, etc. Can be built with buildroot which requires some exploration. Windows users: do this on WSL. These instructions may help (credits: Andrew Jackman). The tools we will use ls: show directory content dd: read/write raw content of a file (or a disk partition) mkfs.ext2: create a new ext2 filesystem debugfs: ext filesystem debugger stat: get file status dumpe2fs: dump ext filesystem info xxd, hexdump: display binary data Step 1. Grab the disk image, mount, & basic inspection The image file is a byte-to-byte dump of a small disk. The disk size is 2MB. # grab the file from this git repo, and unzip it gzip -d disk.img.gz How large is the disk image, compressed and decompressed? $ ls -lh disk.img.gz -rwxr--r-- 1 xzl xzl 2.6K Nov 25 10:39 disk.img.gz $ ls -lh disk.img -rw-r--r-- 1 xzl xzl 2.0M Apr 6 13:33 disk.img Because our filesystem only uses a small fraction of the disk space (we will see soon), most of these bytes are zero. That's why we compress the disk image (as .gz) for distribution. Next, we mount the disk image as a loop device. (Recall: a loop device treats a file as a physical disk; see our lecture slides). # create our mount point $ mkdir /tmp/myfs # mount the disk image. Note the sudo command $ sudo mount -o loop disk.img /tmp/myfs Now we are ready to tinker with the filesystem. Check the disk usage $ df -hP /tmp/myfs/ Filesystem Size Used Avail Use% Mounted on /dev/loop2 2.0M 21K 1.9M 2% /tmp/myfs This shows that our disk size is 2.0M, of which only 2% is used. It shows the mount point (/tmp/myfs) of our filesystem. It also shows that the kernel allocates a loop device ( /dev/loop2 ) as the backing store of the filesystem. The actual device name may vary, e.g. you may see /dev/loop10 . This is the device name of our disk (everything is a file, right?) Check the filesystem type & mount options So, what's the filesystem type? We can use mount , which lists all filesystems currently mounted. From its output, we look for our mount point. $ mount|grep myfs /tmp/disk.img on /tmp/myfs type ext2 (rw,relatime) mount shows our filesystem as ext2. It also shows the mount options (rw=readable & writeable; relatime~=skipping updating a file's access time for most accesses, see details ). List the directory structure $ ls -lh /tmp/myfs/ total 14K -rw-r--r-- 1 root root 10 Apr 6 11:44 aa lrwxrwxrwx 1 root root 2 Apr 6 12:30 aa-symlink -> aa drwx------ 2 root root 12K Apr 2 23:53 lost+found drwxr-xr-x 2 root root 1.0K Apr 6 11:35 testdir Step 2. inspect metadata Recall that an ext2 filesystem has a global \"superblock\", which is the metadata for the entire filesystem. To dump its contents, we of course can write our own program to parse the disk image. But there's already a handy tool -- dumpe2fs . It will accept the disk device name (dev/loop2 in my case; this may be different in your case, see discussion above). $ sudo dumpe2fs /dev/loop2 dumpe2fs 1.42.13 (17-May-2015) Filesystem volume name: <none> Last mounted on: /tmp/myfs Filesystem UUID: 6430eccd-11d0-4ea9-bd26-ce6e946dc02b Filesystem magic number: 0xEF53 Filesystem revision #: 1 (dynamic) Filesystem features: ext_attr resize_inode dir_index filetype sparse_super large_file Filesystem flags: signed_directory_hash Default mount options: user_xattr acl Filesystem state: clean Errors behavior: Continue Filesystem OS type: Linux Inode count: 256 Block count: 2048 Reserved block count: 102 Free blocks: 1990 Free inodes: 244 First block: 1 Block size: 1024 Fragment size: 1024 Reserved GDT blocks: 7 Blocks per group: 8192 Fragments per group: 8192 Inodes per group: 256 Inode blocks per group: 32 Filesystem created: Thu Apr 2 23:53:31 2020 Last mount time: Thu Apr 2 23:56:50 2020 Last write time: Thu Apr 2 23:57:02 2020 Mount count: 2 Maximum mount count: -1 Last checked: Thu Apr 2 23:53:31 2020 Check interval: 0 (<none>) Lifetime writes: 8 kB Reserved blocks uid: 0 (user root) Reserved blocks gid: 0 (group root) First inode: 11 Inode size: 128 Default directory hash: half_md4 Directory Hash Seed: 15323132-fa4b-4822-ab37-f49b15b57487 Group 0: (Blocks 1-2047) Primary superblock at 1, Group descriptors at 2-2 Reserved GDT blocks at 3-9 Block bitmap at 10 (+9), Inode bitmap at 11 (+10) Inode table at 12-43 (+11) 1988 free blocks, 242 free inodes, 3 directories Free blocks: 59-512, 514-2047 Free inodes: 15-256 Metadata overview It's a lot of information! From here, we can see familiar things, echoing what we have learnt about ext2 in class: There are 256 inodes in total (\"Inode count...\"). These inodes are pre-allocated when the filesystem is initialized. There are 2048 blocks (\"Block count...\". Since this disk is 2MB in total, each block is 2MB/2048=1KB) The first inode is inode 11 (\"First inode...)\". Which file is this? We will see soon. Each inode has 128 bytes (\"Inode size...\"). Recall this is for per file metadata plus a bunch of pointers to disk blocks of this file. Block group You also see \"groups\" in the above output. Recall that ext2 partitions all blocks of a disk into groups, so that access within each group has better spatial locality. The output shows that each group can have up to 8192 blocks (\"Blocks per group...\"). As our disk is as small as 2048 blocks, ext2 creates only one group (Group 0), which spans all blocks of the disk. Bitmaps Recall that ext2 use bitmaps to track free/used blocks as well as free/used inodes. In such a bitmap, 1 means used, 0 means free. Where are the bitmaps stored on disk? Check the last few lines of the output. Block bitmap starts from block 10; inode bitmap starts from block 11. Block 12-43 are for the actual inodes. Let's dump the bitmap contents from the disk image. # dump inode bitmap. 256 inodes (display in 32 octets). Bitmap at block 11. $ sudo dd if=/dev/loop2 bs=1024 skip=11 count=1 status=none |xxd -b -l 32 00000000: 11111111 00111111 00000000 00000000 00000000 00000000 .?.... 00000006: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 0000000c: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000012: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000018: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 0000001e: 00000000 00000000 .. # dump block bitmap. 2048 blocks (256 display octets). Bitmap at block 10 $ sudo dd if=/dev/loop2 bs=1024 skip=10 count=1 status=none |xxd -b -l 256 00000000: 11111111 11111111 11111111 11111111 11111111 11111111 ...... 00000006: 11111111 00000011 00000000 00000000 00000000 00000000 ...... 0000000c: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000012: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000018: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 0000001e: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000024: 00000000 00000000 00000000 00000000 00000000 00000000 ...... In the commands above, dd will read the contents of the disk device (note: your /dev/loop device name may vary). \"bs=1024 skip=11 count=1\" means that dd will skip the first 11 blocks and read in 1 block, using 1024 bytes as the block size. note \"blocks\" here are just data blocks for dd to read in; it's orthogonal to disk blocks) The content of the read block is piped to xxd , whose job is to display the content nicely in binary format. \"-b\" means xxd will display every bit . \"-l\" means the number of \"octets\" to display. Each octets is a \"display group\" of eight characters (e.g. \"11111111\"). Since we are display bits, each chaterters is a bit and one octet is a byte. Step 3. Inspect per-file metadata Check the directories again We can use ls to get more information. $ ls -ila total 54 2 drwxr-xr-x 4 root root 1024 Apr 6 11:35 . 5636097 drwxrwxrwt 38 root root 36864 Apr 6 11:35 .. 12 -rw-r--r-- 1 root root 0 Apr 2 23:56 aa 11 drwx------ 2 root root 12288 Apr 2 23:53 lost+found 13 drwxr-xr-x 2 root root 1024 Apr 6 11:35 testdir $ ls -ila testdir/ total 2 13 drwxr-xr-x 2 root root 1024 Apr 6 11:35 . 2 drwxr-xr-x 4 root root 1024 Apr 6 11:35 .. Here \"-i\" means to print the inode number; \"-l\" asks for the long listing format; \"-a\" asks for listing files/dirs that start with \".\" which are normally hidden. In the output, \"total\" shows the number of blocks used by the listed directories. The first column shows the inode number for each file/dir. For instance, inode 12 is for file \"aa\". From dump2efs we know the first inode is inode 11. Do you see it here? Dump inode contents We will use debugfs , which is a powerful debugger for the ext family of filesystems (ext2/3/4). # inode 12. testfile \u201caa\u201d $ sudo debugfs -R \"stat <12>\" /dev/loop2 Inode: 12 Type: regular Mode: 0644 Flags: 0x0 Generation: 4138714773 Version: 0x00000001 User: 0 Group: 0 Size: 10 File ACL: 0 Directory ACL: 0 Links: 1 Blockcount: 2 Fragment: Address: 0 Number: 0 Size: 0 ctime: 0x5e8b4e5f -- Mon Apr 6 11:44:31 2020 atime: 0x5e8b4e4d -- Mon Apr 6 11:44:13 2020 mtime: 0x5e8b4e5f -- Mon Apr 6 11:44:31 2020 BLOCKS: (0):513 TOTAL: 1 # inode 2. root dir $ sudo debugfs -R \"stat <2>\" /dev/loop2 Inode: 2 Type: directory Mode: 0755 Flags: 0x0 Generation: 0 Version: 0x00000002 User: 0 Group: 0 Size: 1024 File ACL: 0 Directory ACL: 0 Links: 4 Blockcount: 2 Fragment: Address: 0 Number: 0 Size: 0 ctime: 0x5e8b4c40 -- Mon Apr 6 11:35:28 2020 atime: 0x5e8b4c41 -- Mon Apr 6 11:35:29 2020 mtime: 0x5e8b4c40 -- Mon Apr 6 11:35:28 2020 BLOCKS: (0):44 TOTAL: 1 To invoke debugfs, we supply the disk device name (e.g. /dev/loop2) and a command (-R ...) that we want debugfs to execute. In this case, our command is \"stat\", which is to dump contents of a given inode, e.g. inode 12 (file \"aa\") and inode 2 (directory \"/\"). More debugfs details here . So much information to see from inodes! File types (\"regular\" and \"directory\"), access times, blocks, etc. These are exactly what we mentioned in the lectures. There are alternative debugfs commands that show same information but in a slight different format: # Showing inodes and type (2=dir, 1=file) $ sudo debugfs -R \"ls -l <2>\" /dev/loop2 2 40755 (2) 0 0 1024 6-Apr-2020 11:35 . 2 40755 (2) 0 0 1024 6-Apr-2020 11:35 .. 11 40700 (2) 0 0 12288 2-Apr-2020 23:53 lost+found 12 100644 (1) 0 0 0 2-Apr-2020 23:56 aa 13 40755 (2) 0 0 1024 6-Apr-2020 11:35 testdir # dump the block IDs used by the root dir $ sudo debugfs -R \"blocks /.\" /dev/loop2 debugfs 1.42.13 (17-May-2015) 44 Keep in mind: all such information comes from inodes. Step 4. Inspect filedata A directory Recall a directory is nothing but a special file. Let's dump the content of the root dir \"/\". We've learnt that the root dir (\"/\") has inode 2. Fire up debugfs! $ sudo debugfs -R \"cat <2>\" /dev/loop2 | hexdump -C debugfs 1.42.13 (17-May-2015) 00000000 02 00 00 00 0c 00 01 02 2e 00 00 00 02 00 00 00 |................| 00000010 0c 00 02 02 2e 2e 00 00 0b 00 00 00 14 00 0a 02 |................| 00000020 6c 6f 73 74 2b 66 6f 75 6e 64 00 00 0c 00 00 00 |lost+found......| 00000030 0c 00 02 01 61 61 00 00 0d 00 00 00 c8 03 07 02 |....aa..........| 00000040 74 65 73 74 64 69 72 00 00 00 00 00 00 00 00 00 |testdir.........| 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| * 00000400 Here, \"cat <2>\" is for debugfs to dump the raw content of file with inode 2. The content is piped to hexdump , which nicely formats the data in hex format. \"-C\" tells hexdump to put hex display (left) and the ASCII display (right) side by side. ASCII is for human to quickly eyeball interesting textual strings. the last row, 0400, mark the end offset of the file. What we see here? \"lost+found\", \"aa\", \"testdir\" ... They are the filenames belonging to \"/\". So, \"/\" indeed stores the names of enclosed files. A regular file inode 12 is for file \"aa\", which has one line \"mycontent\". We could ask debugfs to dump that info. sudo debugfs -R \"cat <12>\" /dev/loop10 | hexdump -C debugfs 1.44.1 (24-Mar-2018) 00000000 6d 79 63 6f 6e 74 65 6e 74 0a |mycontent.| 0000000a Alternatively, we can locate the block of the file (we know it only spans 1 block) and dump the content of that block. $ sudo debugfs -R \"blocks <12>\" /dev/loop2 debugfs 1.42.13 (17-May-2015) 513 # direct inspect block 513 on the disk image $ sudo dd if=/dev/loop2 bs=1024 skip=513 count=1 status=none |hexdump -C 00000000 6d 79 63 6f 6e 74 65 6e 74 0a 00 00 00 00 00 00 |mycontent.......| 00000010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| * 00000400 The first command shows the block is 513. The second command directly dump block 513. We see the content \"mycontent\"! A symbolic link File \"aa-symlink\" is a symbolic link pointing to file \"aa\". $ ls -ila total 55 2 drwxr-xr-x 4 root root 1024 Apr 6 12:30 . 5636097 drwxrwxrwt 38 root root 36864 Apr 6 12:31 .. 12 -rw-r--r-- 1 root root 10 Apr 6 11:44 aa 14 lrwxrwxrwx 1 root root 2 Apr 6 12:30 aa-symlink -> aa 11 drwx------ 2 root root 12288 Apr 2 23:53 lost+found 13 drwxr-xr-x 2 root root 1024 Apr 6 11:35 testdir Recall that a symbolic link is a special file containing the path of another file (\"aa\" in our case). aa-symlink and aa should be two files, i.e. having separate inodes. This is confirmed: inode 12 is for \"aa\" and inode 14 is for \"aa-symlink\". Can we inspect the content of \"aa-symlink\"? We expect to see the string \"aa\" there. However, this seems not as straightforward: xzl@precision[myfs]$ stat aa-symlink File: 'aa-symlink' -> 'aa' Size: 2 Blocks: 0 IO Block: 1024 symbolic link Device: 702h/1794d Inode: 14 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2020-04-06 12:31:13.000000000 -0400 Modify: 2020-04-06 12:30:57.000000000 -0400 Change: 2020-04-06 12:30:57.000000000 -0400 Birth: - So there is not block for \"aa-symlink\" (Blocks: 0)? The reason is that the string is inlined in the inode. So no block is used. Symbolic links are also filesystem objects with inodes. For all symlink shorter than 60 bytes long, the data is stored within the inode itself; it uses the fields which would normally be used to store the pointers to data blocks. This is a worthwhile optimisation as it we avoid allocating a full block for the symlink, and most symlinks are less than 60 characters long. https://www.nongnu.org/ext2-doc/ext2.html Step 0. Initialize the filesystem Why we go back to step 0? Because this is how we created the disk image and initialized the filesystem that we gave to you in the first place. Let's close the loop. Create a disk image xzl@precision[tmp]$ dd if=/dev/zero of=/tmp/disk.img bs=2M count=1 1+0 records in 1+0 records out 2097152 bytes (2.1 MB, 2.0 MiB) copied, 0.00403917 s, 519 MB/s We see dd above. It's a simple tool write/read contents to/from a file. We use it to create a file of 2MB (note bs, the block size). \"if\" means input file, i.e. where we get content from. \"/dev/zero\" is a special (or pseudo) file implemented by the kernel. Whenever you read from it, the kernel will just return 0. As a result, disk.img contains all zeros. Now, \"disk.img\" is just a normal file. Nothing special. Set up a loop device atop the disk image xzl@precision[tmp]$ sudo losetup -fP disk.img xzl@precision[tmp]$ losetup -a /dev/loop1: []: (/tmp/disk.img) To be able to create a filesystem on the disk image, we first ask the kernel to set up a loop device atop the disk image (disk.img). losetup is for this purpose. \"-f\" find the first unused loop device; \"-P\" force scanning the partition table. Details . Initialize an ext2 filesystem $ sudo mkfs.ext2 /dev/loop1 mke2fs 1.42.13 (17-May-2015) Discarding device blocks: done Creating filesystem with 2048 1k blocks and 256 inodes Allocating group tables: done Writing inode tables: done Writing superblocks and filesystem accounting information: done The superblock, all inodes, bitmaps... are created at this moment. We end up having a blank ext2 filesystem. Check our new filesystem is mounted, create the files/dirs for testing (the ones you have tinkered with), and unmount which writes the contents back to disk.img: $ mount |grep myfs /dev/loop1 on /tmp/myfs type ext2 (rw,relatime) $ cd /tmp/myfs $ sudo echo 'test' > aa $ sudo mkdir testdir $ sudo ln -s aa aa-symlink $ sudo umount /tmp/myfs Inspect the disk image $ ls -la disk.img -rw-r--r-- 1 xzl xzl 2097152 Apr 6 13:33 disk.img # the \u201cfile\u201d utility \u2013 smart enough to detect a filesystem within $ file disk.img disk.img: Linux rev 1.0 ext2 filesystem data, UUID=6430eccd-11d0-4ea9-bd26-ce6e946dc02b (large files) # there will be tons of \u20180\u2019s. So zip it for distributing $ gzip disk.img $ ls -la disk.img.gz -rw-r--r-- 1 xzl xzl 2657 Apr 6 13:33 disk.img.gz","title":"lite"},{"location":"lite/#p4-lite-filesystem-inspection","text":"In this lab, we will inspect filesystem images. We will reason about how filedata and metadata are stored and maintained. This is a light version of \"Lab4: filesystem image forensics\".","title":"p4 lite: Filesystem inspection"},{"location":"lite/#objectives","text":"(primary) Reinforcing understanding of ext2 (secondary) Familiarizing with Linux file tools","title":"Objectives"},{"location":"lite/#roadmap","text":"Mount an ext2 filesystem image with a few dir/files. Use Linux tools to examine key data structures: inodes/bitmaps\u2026 Show how such a filesystem image is created","title":"Roadmap"},{"location":"lite/#prerequisites","text":"Required environment Fiddling with a whole filesystem (and disk images) requires the root privilege. Linux/Mac users: do this lab either on your local box which you have root. Or do it on the server, inside a QEMU emulator. The problem with QEMU: you will need a system image with all the utilities, e.g. dumpe2fs, etc. Can be built with buildroot which requires some exploration. Windows users: do this on WSL. These instructions may help (credits: Andrew Jackman). The tools we will use ls: show directory content dd: read/write raw content of a file (or a disk partition) mkfs.ext2: create a new ext2 filesystem debugfs: ext filesystem debugger stat: get file status dumpe2fs: dump ext filesystem info xxd, hexdump: display binary data","title":"Prerequisites"},{"location":"lite/#step-1-grab-the-disk-image-mount-basic-inspection","text":"The image file is a byte-to-byte dump of a small disk. The disk size is 2MB. # grab the file from this git repo, and unzip it gzip -d disk.img.gz How large is the disk image, compressed and decompressed? $ ls -lh disk.img.gz -rwxr--r-- 1 xzl xzl 2.6K Nov 25 10:39 disk.img.gz $ ls -lh disk.img -rw-r--r-- 1 xzl xzl 2.0M Apr 6 13:33 disk.img Because our filesystem only uses a small fraction of the disk space (we will see soon), most of these bytes are zero. That's why we compress the disk image (as .gz) for distribution. Next, we mount the disk image as a loop device. (Recall: a loop device treats a file as a physical disk; see our lecture slides). # create our mount point $ mkdir /tmp/myfs # mount the disk image. Note the sudo command $ sudo mount -o loop disk.img /tmp/myfs Now we are ready to tinker with the filesystem.","title":"Step 1. Grab the disk image, mount, &amp; basic inspection"},{"location":"lite/#check-the-disk-usage","text":"$ df -hP /tmp/myfs/ Filesystem Size Used Avail Use% Mounted on /dev/loop2 2.0M 21K 1.9M 2% /tmp/myfs This shows that our disk size is 2.0M, of which only 2% is used. It shows the mount point (/tmp/myfs) of our filesystem. It also shows that the kernel allocates a loop device ( /dev/loop2 ) as the backing store of the filesystem. The actual device name may vary, e.g. you may see /dev/loop10 . This is the device name of our disk (everything is a file, right?)","title":"Check the disk usage"},{"location":"lite/#check-the-filesystem-type-mount-options","text":"So, what's the filesystem type? We can use mount , which lists all filesystems currently mounted. From its output, we look for our mount point. $ mount|grep myfs /tmp/disk.img on /tmp/myfs type ext2 (rw,relatime) mount shows our filesystem as ext2. It also shows the mount options (rw=readable & writeable; relatime~=skipping updating a file's access time for most accesses, see details ).","title":"Check the filesystem type &amp; mount options"},{"location":"lite/#list-the-directory-structure","text":"$ ls -lh /tmp/myfs/ total 14K -rw-r--r-- 1 root root 10 Apr 6 11:44 aa lrwxrwxrwx 1 root root 2 Apr 6 12:30 aa-symlink -> aa drwx------ 2 root root 12K Apr 2 23:53 lost+found drwxr-xr-x 2 root root 1.0K Apr 6 11:35 testdir","title":"List the directory structure"},{"location":"lite/#step-2-inspect-metadata","text":"Recall that an ext2 filesystem has a global \"superblock\", which is the metadata for the entire filesystem. To dump its contents, we of course can write our own program to parse the disk image. But there's already a handy tool -- dumpe2fs . It will accept the disk device name (dev/loop2 in my case; this may be different in your case, see discussion above). $ sudo dumpe2fs /dev/loop2 dumpe2fs 1.42.13 (17-May-2015) Filesystem volume name: <none> Last mounted on: /tmp/myfs Filesystem UUID: 6430eccd-11d0-4ea9-bd26-ce6e946dc02b Filesystem magic number: 0xEF53 Filesystem revision #: 1 (dynamic) Filesystem features: ext_attr resize_inode dir_index filetype sparse_super large_file Filesystem flags: signed_directory_hash Default mount options: user_xattr acl Filesystem state: clean Errors behavior: Continue Filesystem OS type: Linux Inode count: 256 Block count: 2048 Reserved block count: 102 Free blocks: 1990 Free inodes: 244 First block: 1 Block size: 1024 Fragment size: 1024 Reserved GDT blocks: 7 Blocks per group: 8192 Fragments per group: 8192 Inodes per group: 256 Inode blocks per group: 32 Filesystem created: Thu Apr 2 23:53:31 2020 Last mount time: Thu Apr 2 23:56:50 2020 Last write time: Thu Apr 2 23:57:02 2020 Mount count: 2 Maximum mount count: -1 Last checked: Thu Apr 2 23:53:31 2020 Check interval: 0 (<none>) Lifetime writes: 8 kB Reserved blocks uid: 0 (user root) Reserved blocks gid: 0 (group root) First inode: 11 Inode size: 128 Default directory hash: half_md4 Directory Hash Seed: 15323132-fa4b-4822-ab37-f49b15b57487 Group 0: (Blocks 1-2047) Primary superblock at 1, Group descriptors at 2-2 Reserved GDT blocks at 3-9 Block bitmap at 10 (+9), Inode bitmap at 11 (+10) Inode table at 12-43 (+11) 1988 free blocks, 242 free inodes, 3 directories Free blocks: 59-512, 514-2047 Free inodes: 15-256","title":"Step 2. inspect metadata"},{"location":"lite/#metadata-overview","text":"It's a lot of information! From here, we can see familiar things, echoing what we have learnt about ext2 in class: There are 256 inodes in total (\"Inode count...\"). These inodes are pre-allocated when the filesystem is initialized. There are 2048 blocks (\"Block count...\". Since this disk is 2MB in total, each block is 2MB/2048=1KB) The first inode is inode 11 (\"First inode...)\". Which file is this? We will see soon. Each inode has 128 bytes (\"Inode size...\"). Recall this is for per file metadata plus a bunch of pointers to disk blocks of this file.","title":"Metadata overview"},{"location":"lite/#block-group","text":"You also see \"groups\" in the above output. Recall that ext2 partitions all blocks of a disk into groups, so that access within each group has better spatial locality. The output shows that each group can have up to 8192 blocks (\"Blocks per group...\"). As our disk is as small as 2048 blocks, ext2 creates only one group (Group 0), which spans all blocks of the disk.","title":"Block group"},{"location":"lite/#bitmaps","text":"Recall that ext2 use bitmaps to track free/used blocks as well as free/used inodes. In such a bitmap, 1 means used, 0 means free. Where are the bitmaps stored on disk? Check the last few lines of the output. Block bitmap starts from block 10; inode bitmap starts from block 11. Block 12-43 are for the actual inodes. Let's dump the bitmap contents from the disk image. # dump inode bitmap. 256 inodes (display in 32 octets). Bitmap at block 11. $ sudo dd if=/dev/loop2 bs=1024 skip=11 count=1 status=none |xxd -b -l 32 00000000: 11111111 00111111 00000000 00000000 00000000 00000000 .?.... 00000006: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 0000000c: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000012: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000018: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 0000001e: 00000000 00000000 .. # dump block bitmap. 2048 blocks (256 display octets). Bitmap at block 10 $ sudo dd if=/dev/loop2 bs=1024 skip=10 count=1 status=none |xxd -b -l 256 00000000: 11111111 11111111 11111111 11111111 11111111 11111111 ...... 00000006: 11111111 00000011 00000000 00000000 00000000 00000000 ...... 0000000c: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000012: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000018: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 0000001e: 00000000 00000000 00000000 00000000 00000000 00000000 ...... 00000024: 00000000 00000000 00000000 00000000 00000000 00000000 ...... In the commands above, dd will read the contents of the disk device (note: your /dev/loop device name may vary). \"bs=1024 skip=11 count=1\" means that dd will skip the first 11 blocks and read in 1 block, using 1024 bytes as the block size. note \"blocks\" here are just data blocks for dd to read in; it's orthogonal to disk blocks) The content of the read block is piped to xxd , whose job is to display the content nicely in binary format. \"-b\" means xxd will display every bit . \"-l\" means the number of \"octets\" to display. Each octets is a \"display group\" of eight characters (e.g. \"11111111\"). Since we are display bits, each chaterters is a bit and one octet is a byte.","title":"Bitmaps"},{"location":"lite/#step-3-inspect-per-file-metadata","text":"","title":"Step 3. Inspect per-file metadata"},{"location":"lite/#check-the-directories-again","text":"We can use ls to get more information. $ ls -ila total 54 2 drwxr-xr-x 4 root root 1024 Apr 6 11:35 . 5636097 drwxrwxrwt 38 root root 36864 Apr 6 11:35 .. 12 -rw-r--r-- 1 root root 0 Apr 2 23:56 aa 11 drwx------ 2 root root 12288 Apr 2 23:53 lost+found 13 drwxr-xr-x 2 root root 1024 Apr 6 11:35 testdir $ ls -ila testdir/ total 2 13 drwxr-xr-x 2 root root 1024 Apr 6 11:35 . 2 drwxr-xr-x 4 root root 1024 Apr 6 11:35 .. Here \"-i\" means to print the inode number; \"-l\" asks for the long listing format; \"-a\" asks for listing files/dirs that start with \".\" which are normally hidden. In the output, \"total\" shows the number of blocks used by the listed directories. The first column shows the inode number for each file/dir. For instance, inode 12 is for file \"aa\". From dump2efs we know the first inode is inode 11. Do you see it here?","title":"Check the directories again"},{"location":"lite/#dump-inode-contents","text":"We will use debugfs , which is a powerful debugger for the ext family of filesystems (ext2/3/4). # inode 12. testfile \u201caa\u201d $ sudo debugfs -R \"stat <12>\" /dev/loop2 Inode: 12 Type: regular Mode: 0644 Flags: 0x0 Generation: 4138714773 Version: 0x00000001 User: 0 Group: 0 Size: 10 File ACL: 0 Directory ACL: 0 Links: 1 Blockcount: 2 Fragment: Address: 0 Number: 0 Size: 0 ctime: 0x5e8b4e5f -- Mon Apr 6 11:44:31 2020 atime: 0x5e8b4e4d -- Mon Apr 6 11:44:13 2020 mtime: 0x5e8b4e5f -- Mon Apr 6 11:44:31 2020 BLOCKS: (0):513 TOTAL: 1 # inode 2. root dir $ sudo debugfs -R \"stat <2>\" /dev/loop2 Inode: 2 Type: directory Mode: 0755 Flags: 0x0 Generation: 0 Version: 0x00000002 User: 0 Group: 0 Size: 1024 File ACL: 0 Directory ACL: 0 Links: 4 Blockcount: 2 Fragment: Address: 0 Number: 0 Size: 0 ctime: 0x5e8b4c40 -- Mon Apr 6 11:35:28 2020 atime: 0x5e8b4c41 -- Mon Apr 6 11:35:29 2020 mtime: 0x5e8b4c40 -- Mon Apr 6 11:35:28 2020 BLOCKS: (0):44 TOTAL: 1 To invoke debugfs, we supply the disk device name (e.g. /dev/loop2) and a command (-R ...) that we want debugfs to execute. In this case, our command is \"stat\", which is to dump contents of a given inode, e.g. inode 12 (file \"aa\") and inode 2 (directory \"/\"). More debugfs details here . So much information to see from inodes! File types (\"regular\" and \"directory\"), access times, blocks, etc. These are exactly what we mentioned in the lectures. There are alternative debugfs commands that show same information but in a slight different format: # Showing inodes and type (2=dir, 1=file) $ sudo debugfs -R \"ls -l <2>\" /dev/loop2 2 40755 (2) 0 0 1024 6-Apr-2020 11:35 . 2 40755 (2) 0 0 1024 6-Apr-2020 11:35 .. 11 40700 (2) 0 0 12288 2-Apr-2020 23:53 lost+found 12 100644 (1) 0 0 0 2-Apr-2020 23:56 aa 13 40755 (2) 0 0 1024 6-Apr-2020 11:35 testdir # dump the block IDs used by the root dir $ sudo debugfs -R \"blocks /.\" /dev/loop2 debugfs 1.42.13 (17-May-2015) 44 Keep in mind: all such information comes from inodes.","title":"Dump inode contents"},{"location":"lite/#step-4-inspect-filedata","text":"","title":"Step 4. Inspect filedata"},{"location":"lite/#a-directory","text":"Recall a directory is nothing but a special file. Let's dump the content of the root dir \"/\". We've learnt that the root dir (\"/\") has inode 2. Fire up debugfs! $ sudo debugfs -R \"cat <2>\" /dev/loop2 | hexdump -C debugfs 1.42.13 (17-May-2015) 00000000 02 00 00 00 0c 00 01 02 2e 00 00 00 02 00 00 00 |................| 00000010 0c 00 02 02 2e 2e 00 00 0b 00 00 00 14 00 0a 02 |................| 00000020 6c 6f 73 74 2b 66 6f 75 6e 64 00 00 0c 00 00 00 |lost+found......| 00000030 0c 00 02 01 61 61 00 00 0d 00 00 00 c8 03 07 02 |....aa..........| 00000040 74 65 73 74 64 69 72 00 00 00 00 00 00 00 00 00 |testdir.........| 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| * 00000400 Here, \"cat <2>\" is for debugfs to dump the raw content of file with inode 2. The content is piped to hexdump , which nicely formats the data in hex format. \"-C\" tells hexdump to put hex display (left) and the ASCII display (right) side by side. ASCII is for human to quickly eyeball interesting textual strings. the last row, 0400, mark the end offset of the file. What we see here? \"lost+found\", \"aa\", \"testdir\" ... They are the filenames belonging to \"/\". So, \"/\" indeed stores the names of enclosed files.","title":"A directory"},{"location":"lite/#a-regular-file","text":"inode 12 is for file \"aa\", which has one line \"mycontent\". We could ask debugfs to dump that info. sudo debugfs -R \"cat <12>\" /dev/loop10 | hexdump -C debugfs 1.44.1 (24-Mar-2018) 00000000 6d 79 63 6f 6e 74 65 6e 74 0a |mycontent.| 0000000a Alternatively, we can locate the block of the file (we know it only spans 1 block) and dump the content of that block. $ sudo debugfs -R \"blocks <12>\" /dev/loop2 debugfs 1.42.13 (17-May-2015) 513 # direct inspect block 513 on the disk image $ sudo dd if=/dev/loop2 bs=1024 skip=513 count=1 status=none |hexdump -C 00000000 6d 79 63 6f 6e 74 65 6e 74 0a 00 00 00 00 00 00 |mycontent.......| 00000010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| * 00000400 The first command shows the block is 513. The second command directly dump block 513. We see the content \"mycontent\"!","title":"A regular file"},{"location":"lite/#a-symbolic-link","text":"File \"aa-symlink\" is a symbolic link pointing to file \"aa\". $ ls -ila total 55 2 drwxr-xr-x 4 root root 1024 Apr 6 12:30 . 5636097 drwxrwxrwt 38 root root 36864 Apr 6 12:31 .. 12 -rw-r--r-- 1 root root 10 Apr 6 11:44 aa 14 lrwxrwxrwx 1 root root 2 Apr 6 12:30 aa-symlink -> aa 11 drwx------ 2 root root 12288 Apr 2 23:53 lost+found 13 drwxr-xr-x 2 root root 1024 Apr 6 11:35 testdir Recall that a symbolic link is a special file containing the path of another file (\"aa\" in our case). aa-symlink and aa should be two files, i.e. having separate inodes. This is confirmed: inode 12 is for \"aa\" and inode 14 is for \"aa-symlink\". Can we inspect the content of \"aa-symlink\"? We expect to see the string \"aa\" there. However, this seems not as straightforward: xzl@precision[myfs]$ stat aa-symlink File: 'aa-symlink' -> 'aa' Size: 2 Blocks: 0 IO Block: 1024 symbolic link Device: 702h/1794d Inode: 14 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2020-04-06 12:31:13.000000000 -0400 Modify: 2020-04-06 12:30:57.000000000 -0400 Change: 2020-04-06 12:30:57.000000000 -0400 Birth: - So there is not block for \"aa-symlink\" (Blocks: 0)? The reason is that the string is inlined in the inode. So no block is used. Symbolic links are also filesystem objects with inodes. For all symlink shorter than 60 bytes long, the data is stored within the inode itself; it uses the fields which would normally be used to store the pointers to data blocks. This is a worthwhile optimisation as it we avoid allocating a full block for the symlink, and most symlinks are less than 60 characters long. https://www.nongnu.org/ext2-doc/ext2.html","title":"A symbolic link"},{"location":"lite/#step-0-initialize-the-filesystem","text":"Why we go back to step 0? Because this is how we created the disk image and initialized the filesystem that we gave to you in the first place. Let's close the loop.","title":"Step 0. Initialize the filesystem"},{"location":"lite/#create-a-disk-image","text":"xzl@precision[tmp]$ dd if=/dev/zero of=/tmp/disk.img bs=2M count=1 1+0 records in 1+0 records out 2097152 bytes (2.1 MB, 2.0 MiB) copied, 0.00403917 s, 519 MB/s We see dd above. It's a simple tool write/read contents to/from a file. We use it to create a file of 2MB (note bs, the block size). \"if\" means input file, i.e. where we get content from. \"/dev/zero\" is a special (or pseudo) file implemented by the kernel. Whenever you read from it, the kernel will just return 0. As a result, disk.img contains all zeros. Now, \"disk.img\" is just a normal file. Nothing special.","title":"Create a disk image"},{"location":"lite/#set-up-a-loop-device-atop-the-disk-image","text":"xzl@precision[tmp]$ sudo losetup -fP disk.img xzl@precision[tmp]$ losetup -a /dev/loop1: []: (/tmp/disk.img) To be able to create a filesystem on the disk image, we first ask the kernel to set up a loop device atop the disk image (disk.img). losetup is for this purpose. \"-f\" find the first unused loop device; \"-P\" force scanning the partition table. Details .","title":"Set up a loop device atop the disk image"},{"location":"lite/#initialize-an-ext2-filesystem","text":"$ sudo mkfs.ext2 /dev/loop1 mke2fs 1.42.13 (17-May-2015) Discarding device blocks: done Creating filesystem with 2048 1k blocks and 256 inodes Allocating group tables: done Writing inode tables: done Writing superblocks and filesystem accounting information: done The superblock, all inodes, bitmaps... are created at this moment. We end up having a blank ext2 filesystem. Check our new filesystem is mounted, create the files/dirs for testing (the ones you have tinkered with), and unmount which writes the contents back to disk.img: $ mount |grep myfs /dev/loop1 on /tmp/myfs type ext2 (rw,relatime) $ cd /tmp/myfs $ sudo echo 'test' > aa $ sudo mkdir testdir $ sudo ln -s aa aa-symlink $ sudo umount /tmp/myfs","title":"Initialize an ext2 filesystem"},{"location":"lite/#inspect-the-disk-image","text":"$ ls -la disk.img -rw-r--r-- 1 xzl xzl 2097152 Apr 6 13:33 disk.img # the \u201cfile\u201d utility \u2013 smart enough to detect a filesystem within $ file disk.img disk.img: Linux rev 1.0 ext2 filesystem data, UUID=6430eccd-11d0-4ea9-bd26-ce6e946dc02b (large files) # there will be tons of \u20180\u2019s. So zip it for distributing $ gzip disk.img $ ls -la disk.img.gz -rw-r--r-- 1 xzl xzl 2657 Apr 6 13:33 disk.img.gz","title":"Inspect the disk image"},{"location":"wsl/","text":"Setting up Windows WSL for the experiment Dec/11/2020. Contributed by Andrew Jackman (aj6eb). (Felix: These are verified to work. Some steps may be overkill though. TODO: validate & simplify. ) Install WSL see https://docs.microsoft.com/en-us/windows/wsl/install-win10 You want to opt in to the dev builds for windows insider program to get a build capable of the simplified install if you want to go that route. Taking the more involved manual option doesnt look to bad either Get Ubuntu version from Microsoft store (I chose v20.04 LTS) If you run into a sudo command that will not run because of conflicts with bash then take a look at https://askubuntu.com/questions/103643/cannot-echo-hello-x-txt-even-with-sudo Commands for hard linking (I know we talked about it in class but I couldn't remember which session) https://www.cyberciti.biz/faq/creating-hard-links-with-ln-command/","title":"Wsl"},{"location":"wsl/#setting-up-windows-wsl-for-the-experiment","text":"Dec/11/2020. Contributed by Andrew Jackman (aj6eb). (Felix: These are verified to work. Some steps may be overkill though. TODO: validate & simplify. ) Install WSL see https://docs.microsoft.com/en-us/windows/wsl/install-win10 You want to opt in to the dev builds for windows insider program to get a build capable of the simplified install if you want to go that route. Taking the more involved manual option doesnt look to bad either Get Ubuntu version from Microsoft store (I chose v20.04 LTS) If you run into a sudo command that will not run because of conflicts with bash then take a look at https://askubuntu.com/questions/103643/cannot-echo-hello-x-txt-even-with-sudo Commands for hard linking (I know we talked about it in class but I couldn't remember which session) https://www.cyberciti.biz/faq/creating-hard-links-with-ln-command/","title":"Setting up Windows WSL for the experiment"}]}